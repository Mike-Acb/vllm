name: Build vLLM CPU (from fork)

on:
  # 手动触发：可自定义镜像 tag、是否多架构
  workflow_dispatch:
    inputs:
      image_tag:
        description: "镜像 tag（默认用短 SHA）"
        required: false
        default: ""
      platforms:
        description: "目标平台（逗号分隔），默认 amd64,arm64"
        required: false
        default: "linux/amd64,linux/arm64"
  # 推到 main 或打 tag 会自动构建
  push:
    branches: ["main", "master"]
    tags: ["v*.*.*"]

permissions:
  contents: read
  packages: write
  id-token: write

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}/vllm-cpu   # ghcr.io/<owner>/<repo>/vllm-cpu

jobs:
  build-and-push:
    runs-on: ubuntu-24.04
    timeout-minutes: 90

    steps:
      - name: Checkout (your fork)
        uses: actions/checkout@v4

      - name: Set up QEMU (for multi-arch)
        uses: docker/setup-qemu-action@v3

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to GHCR
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Compute image tags
        id: meta
        run: |
          REPO=$(echo "${GITHUB_REPOSITORY}" | tr '[:upper:]' '[:lower:]')
          echo "tags=ghcr.io/${REPO}/vllm-cpu:latest" >> $GITHUB_OUTPUT

      - name: Build and push (multi-arch)
        uses: docker/build-push-action@v6
        with:
          context: .
          file: ./.docker/Dockerfile.cpu
          # 如果你的 Dockerfile 里有多阶段并且需要特定 target（如 vllm-openai），取消下一行注释
          # target: vllm-openai
          push: true
          platforms: ${{ inputs.platforms || 'linux/amd64,linux/arm64' }}
          tags: ${{ steps.meta.outputs.tags }}
          # 可按需透传构建参数（示例）
          # build-args: |
          #   max_jobs=8
          #   VLLM_VERSION=v0.9.2
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Print pushed images
        run: |
          echo "Pushed: ${{ steps.meta.outputs.tags }}"
